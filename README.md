# Arbol
1. Configuración: se definen constantes como la ruta del archivo, el número de ejecuciones (50) y el tamaño del conjunto de prueba (30%).
2. Carga de Datos: Se lee el archivo CSV llamado dataset_correos.csv.
3. Preprocesamiento: Se identifican las columnas numéricas y categóricas. Se establece un ColumnTransformer que aplica StandardScaler (si APPLY_ZSCORE es verdadero) a las columnas numéricas y OneHotEncoder a las categóricas. Además, se convierten las etiquetas de clasificación (spam/ham) a un formato binario (0/1 o spam/ham).
4. Modelo y Pipeline: Se crea un clasificador de árbol de decisión (DecisionTreeClassifier) y se combina el preprocesador con el clasificador en un Pipeline. Esto asegura que el preprocesamiento se aplique correctamente en cada iteración de la validación.
5. Bucle de Entrenamiento y Evaluación: Se utiliza StratifiedShuffleSplit para generar 50 pares de conjuntos de entrenamiento y prueba. Este método mantiene la proporción de las clases (spam/ham) en cada partición, lo cual es crucial para datos desequilibrados. En cada iteración, el pipeline se entrena y se utiliza para hacer predicciones. Se calculan las métricas de exactitud y puntuación F1 en el conjunto de prueba, y se almacenan.
6. Resultados y Visualización: Se imprimen las estadísticas (media, desviación estándar, mínimo y máximo) de las métricas de las 50 ejecuciones, lo que muestra la estabilidad del modelo. Se identifican y muestran los detalles de la mejor y la peor ejecución basándose en la puntuación F1. Además, se generan y muestran dos gráficos: una curva de exactitud por ejecución y un histograma de la distribución de exactitud.
El objetivo principal de ejecutar el modelo 50 veces no es encontrar la "mejor" partición, sino comprender la robustez y estabilidad del modelo. La media de las métricas (exactitud y F1) proporciona una idea del rendimiento general del modelo, mientras que la desviación estándar indica qué tan consistente es.
